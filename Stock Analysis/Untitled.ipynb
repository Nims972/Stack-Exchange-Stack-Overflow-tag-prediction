{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn import preprocessing\n",
    "# Stock price daily data is taken from https://www.alphavantage.co/ API from 1995 to up til now of AAPL stocks\n",
    "url = 'https://www.alphavantage.co/query'\n",
    "params = {\n",
    "    'function': 'TIME_SERIES_DAILY',\n",
    "    'symbol': 'AAPL',\n",
    "    'outputsize': 'full',\n",
    "    'apikey': '5COC2L9JP8SMNM41'\n",
    "}\n",
    "\n",
    "\n",
    "class Harvesting:\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "\n",
    "    def load_data(self, flag=True, url=url, params=params):\n",
    "        if flag:\n",
    "            self.data = pd.read_csv('data/DAT_ASCII_EURUSD_M1_2017.csv', sep=';')\n",
    "            return self.data\n",
    "\n",
    "        else:\n",
    "            date = []\n",
    "            close = []\n",
    "            high = []\n",
    "            low = []\n",
    "            volume = []\n",
    "            open = []\n",
    "            if 'data.csv' in os.listdir('data'):\n",
    "                df = pd.read_csv('data/data.csv', sep=';')\n",
    "\n",
    "            else:\n",
    "                # get the data from api\n",
    "                try:\n",
    "                    api_data = requests.get(url, params=params).json()\n",
    "                    for i in api_data['Time Series (Daily)']:\n",
    "                        dt = i\n",
    "                        p = api_data['Time Series (Daily)'][i]\n",
    "\n",
    "                        open_value = np.float32(p['1. open'])\n",
    "                        high_value = np.float32(p['2. high'])\n",
    "                        low_value = np.float32(p['3. low'])\n",
    "                        close_value = np.float32(p['4. close'])\n",
    "                        volume_value = np.float32(p['5. volume'])\n",
    "                        date.append(dt)\n",
    "                        close.append(close_value)\n",
    "                        high.append(high_value)\n",
    "                        open.append(open_value)\n",
    "                        low.append(low_value)\n",
    "                        volume.append(volume_value)\n",
    "\n",
    "                except:\n",
    "                    print(\"Network connection error or wrong url\")\n",
    "                    return\n",
    "                df = pd.DataFrame(data={'date': date, 'open': open,\n",
    "                                        'high': high, 'low': low,\n",
    "                                        'close': close, 'volume': volume\n",
    "                                        })\n",
    "                df.to_csv('data/data.csv', sep=';')\n",
    "\n",
    "            self.data = df\n",
    "\n",
    "            return self.data\n",
    "\n",
    "    def scale(self, timeseries):\n",
    "        if self.mean is None or self.std is None:\n",
    "            self.mean = np.mean(np.array(self.data['close']))\n",
    "            self.std = np.std(np.array(self.data['close']))\n",
    "\n",
    "        return (timeseries - self.mean) / self.std\n",
    "\n",
    "    def unscale(self, Y):\n",
    "        return Y * self.std + self.mean\n",
    "\n",
    "    def split_into_chunks(self, train, predict, step, binary=False, scale=True):\n",
    "        X = []\n",
    "        Y = []\n",
    "        for i in range(0, len(self.data), step):\n",
    "            try:\n",
    "                x_i = np.array(self.data['close'][i:i + train])\n",
    "                y_i = self.data['close'][i + train + predict]\n",
    "\n",
    "                if binary:\n",
    "                    # for stock price hike or fall [hike, fall]\n",
    "                    if y_i > 0:\n",
    "                        y_i = [1., 0.]\n",
    "\n",
    "                    else:\n",
    "                        y_i = [0., 1.]\n",
    "\n",
    "                else:\n",
    "                    timeseries = np.array(self.data['close'][i:i + train + predict])\n",
    "                    timeseries = self.scale(timeseries)\n",
    "                    x_i = timeseries[:-predict]\n",
    "                    y_i = timeseries[-predict:]\n",
    "            except: break\n",
    "            X.append(x_i)\n",
    "            Y.append(y_i)\n",
    "\n",
    "        print('total chunks ', len(X))\n",
    "        print('each chunk contains', len(X[0]))\n",
    "\n",
    "        print('saving to data/data1.csv')\n",
    "        np.savetxt(\"data/data1.csv\", X, delimiter=',')\n",
    "        return np.array(X), np.array(Y)\n",
    "\n",
    "    @staticmethod\n",
    "    def data_split(X, Y, split_ratio=0.1):\n",
    "\n",
    "        def reform_data(xi):\n",
    "            return xi.reshape(-1, 1)\n",
    "\n",
    "        X = np.apply_along_axis(reform_data, 1, X)\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "            X, Y, test_size=split_ratio)\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
